# -*- coding: utf-8 -*-
"""PredictiveAniltycs-Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n3wEkrXAOKftfP3oilyoMXlA24TAzGsk

# Proyek Predictive Analytics: [Diabetes prediction dataset]
- **Nama:** [Sinta Ezra Wati Gulo]
- **Email:** [sintaezra04@gmail.com]
- **ID Dicoding:** [sinta_ezra]

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV

"""## Data Understanding

Selanjutnya adalah memahami data, untuk memahami data dapat dilakukan dalam beberapa tahapan berikut:

- Data loading
- Exploratory Data Analysis - Deskripsi Variabel
- Exploratory Data Analysis - Menangani Missing Value dan Outliers
- Exploratory Data Analysis - Univariate Analysis
- Exploratory Data Analysis - Multivariate Analysis

### Data Loading
"""

# Load dataset
df = pd.read_csv('data/diabetes_prediction_dataset.csv')

# Melihat data
df

"""Output kode di atas memberikan informasi sebagai berikut:

- Ada 100.000 baris dalam dataset.
- Terdapat 9 kolom yaitu: `gender, age, hypertension, heart_disease, smoking_history, bmi, HbA1c_level, blood_glucose_level`, dan `diabetes`.

### Exploratory Data Analysis - Deskripsi Variabel

Berdasarkan informasi dari Kaggle, variabel-variabel pada Diabetes prediction dataset adalah sebagai berikut:
* `gender`: mengacu pada jenis kelamin biologis seseorang, yang dapat memengaruhi kerentanan terhadap diabetes. Terdapat tiga kategori: laki-laki, perempuan, dan lainnya.
* `age`: faktor penting karena diabetes lebih sering terdiagnosis pada orang dewasa yang lebih tua. Rentang usia dalam dataset ini adalah 0–80 tahun.
* `hypertension`: kondisi medis di mana tekanan darah dalam arteri terus-menerus tinggi. Bernilai 0 atau 1, di mana: 0 berarti tidak memiliki hipertensi dan 1 berarti memiliki hipertensi.
* `heart_disease`:  kondisi medis lain yang berkaitan dengan peningkatan risiko diabetes. Bernilai 0 atau 1, di mana: 0 berarti tidak memiliki penyakit jantung dan 1 berarti memiliki penyakit jantung.
* `smoking_history`: riwayat merokok juga dianggap sebagai faktor risiko diabetes dan dapat memperburuk komplikasi diabetes. Dalam dataset ini, terdapat 6 kategori yaitu not current, former, No Info, current, never, dan ever.
* `bmi `: ukuran lemak tubuh berdasarkan berat dan tinggi badan. Nilai BMI yang tinggi dikaitkan dengan risiko diabetes yang lebih besar Rentang BMI dalam dataset adalah 10.16 – 71.55. Kategori BMI pada dataset ini yaitu <18.5 = berat badan kurang, 18.5–24.9 = normal, 25–29.9 = kelebihan berat badan, dan ≥30 = obesitas.
* `HbA1c_level`: HbA1c (Hemoglobin A1c) mengukur rata-rata kadar gula darah selama 2–3 bulan terakhir. Nilai yang lebih tinggi menunjukkan risiko lebih besar terkena diabetes.
Umumnya, HbA1c > 6.5% menunjukkan diabetes.
* `blood_glucose_level`:  mengacu pada jumlah gula dalam aliran darah pada satu waktu. Kadar glukosa darah yang tinggi merupakan indikator utama diabetes.
* `diabetes`: variabel target yang diprediksi dalam dataset, dengan 1 menunjukkan menderita diabetes dan 0 menunjukkan tidak menderita diabetes.
"""

df.info()

"""Dari output terlihat bahwa:

* Terdapat 2 kolom dengan tipe object, yaitu: `gender dan smoking_history`. Kolom ini merupakan categorical features pada dataset ini.
* Terdapat 3 kolom numerik dengan tipe data float64 yaitu: `age, bmi, dan HbA1c_level`.
* Terdapat 4 kolom numerik dengan tipe data int64, yaitu: `hypertension, heart_disease, blood_glucose_level, dan diabetes`.
"""

print('Jumlah data duplikat:', df.duplicated().sum())

df[df.duplicated()]

df = df.drop_duplicates()
print("Jumlah baris setelah hapus duplikat:", df.shape[0])

df.describe()

"""**Insight:**

- Hasil di atas menunjukkan deskripsi statistik untuk masing-masing fitur. Rata-rata usia (age) adalah sekitar 41.79 tahun, dengan rentang antara 0.08 hingga 80 tahun, menunjukkan variasi usia yang luas.
- Nilai BMI memiliki rata-rata 27.32, yang menunjukkan bahwa sebagian besar peserta berada pada kategori overweight, dengan nilai maksimum ekstrim hingga 95.69, yang patut dicurigai sebagai outlier.
- Untuk HbA1c_level, nilai rata-ratanya adalah 5.53, dengan 75% data di bawah 6.2, mendekati ambang diagnosis diabetes.
- Sementara itu, kadar glukosa darah (blood_glucose_level) rata-ratanya adalah 138.21, yang berada pada ambang batas toleransi normal.
- Target diabetes memiliki nilai rata-rata 0.088, yang berarti sekitar 8.8% dari total populasi adalah penderita diabetes.

Secara keseluruhan, statistik ini menunjukkan bahwa dataset memiliki keragaman yang cukup tinggi pada usia dan BMI, dan sebagian besar pasien tidak memiliki penyakit penyerta (hipertensi/penyakit jantung).

### Exploratory Data Analysis - Menangani Missing Value dan Outliers

**Menangani Missing Value**
"""

# Mengganti No Info pada kolom smoking_history dengan NaN
df['smoking_history'] = df['smoking_history'].replace('No Info', np.nan)

"""Hal di atas dilakukan agar 'No Info' pada kolom smoking_history dapat diperlakukan sebagai missing value secara eksplisit. Hal ini dapat memudahkan proses imputasi atau penanganan data hilang di tahap berikutnya."""

df.isna().sum()

df['smoking_history'] = df['smoking_history'].fillna('Missing')

""" Selanjutnya mengisi missing value pada kolom smoking_history dengan label 'Missing' sebagai kategori khusus untuk memudahkan proses encoding dan memastikan semua data tetap digunakan dalam modeling. Tujuannya adalah agar siap untuk proses encoding dan tidak menghilangkan data."""

# Memeriksa kembali apakah masih ada missing value atau tidak
df.isna().sum()

"""**Menangani Outliers**

Sebelum menangani outliers, disini akan dilakukan visualisasi data terlebih dahulu dengan boxplot untuk mendeteksi outliers pada fitur numerik.
"""

sns.boxplot(x=df['age'])

sns.boxplot(x=df['hypertension'])

sns.boxplot(x=df['heart_disease'])

sns.boxplot(x=df['bmi'])

sns.boxplot(x=df['HbA1c_level'])

sns.boxplot(x=df['blood_glucose_level'])

"""**Insight:**
<br>Pada visualisasi bloxpot pada fitur-fitur numerik di atas, dapat kita lihat bahwa pada beberapa fitur numerik terdapat outliers.
"""

# Ambil hanya kolom numerikal tertentu
num_cols = [ 'bmi', 'HbA1c_level', 'blood_glucose_level']
numeric_cols = [col for col in num_cols if col in df.columns]

# Hitung Q1, Q3, dan IQR hanya untuk kolom numerikal
Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filter_outliers = ~((df[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
df = df[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
df.shape

"""Output di atas menunjukkan bahwa dataset sekarang telah bersih dan memiliki 88.195 sampel.

### Exploratory Data Analysis - Univariate Analysis

Pada tahap ini akan dilakukan proses analisis data dengan teknik Univariate EDA. Dimana disini data akan dibagi menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']
categorical_features = ['gender', 'smoking_history']

"""**Categorical Features**"""

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_copy = df.copy()
df_copy = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_copy)
count.plot(kind='bar', title=feature);

"""**Insight**:

Terdapat 3 kategori pada fitur gender, secara berurutan dari jumlahnya yang paling banyak yaitu: Female, Male, dan Other. Dari data persentase dapat kita simpulkan bahwa ebagian besar data didominasi oleh gender Female (58%), diikuti oleh Male (42%), sementara kategori Other hampir tidak signifikan karena hanya mencakup 0.0% dari total data (hanya 18 sampel).
"""

feature = categorical_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_copy = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_copy)
count.plot(kind='bar', title=feature);

"""**Insight:**

Terdapat 6 kategori pada fitur gender, secara berurutan dari jumlahnya yang paling banyak yaitu: never, Missing, current, former, not current, dan ever. Mayoritas data berasal dari individu yang tidak pernah merokok (kategori never) sebesar 35.4%. Selain itu, proporsi terbesar berikutnya memiliki riwayat merokok yang tidak diketahui atau tidak diisi (kategori Missing) sebanyak 35.3%, yang berarti terdapat kekosongan informasi yang cukup besar dalam fitur ini. Kategori lainnya menunjukkan bahwa sebagian kecil populasi merupakan perokok aktif atau mantan perokok.

**Numerical Features**
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""**Insight:**

1. Fitur `age`
- Distribusi usia cukup merata dari usia muda hingga sekitar usia 70 tahun.
- Terlihat lonjakan signifikan pada usia 80 tahun, yang kemungkinan besar disebabkan oleh banyaknya data dengan nilai maksimum default (mungkin karena kesalahan pengisian atau default value).
- Secara keseluruhan, distribusinya mendekati uniform dengan outlier mencolok di usia 80.
2. Fitur `hypertension` & `heart_disease`
- Histogram menunjukkan bahwa sebagian besar individu dalam dataset memiliki nilai 0, artinya mayoritas tidak menderita hipertensi maupun penyakit jantung.
- Distribusi yang sangat tidak merata ini menandakan bahwa kedua fitur ini sangat tidak seimbang (imbalanced).
3. Fitur `bmi`
- Terlihat distribusi normal di kisaran 15–40.
- Namun, ada spike ekstrem di satu nilai (sekitar 28), menandakan banyak nilai BMI yang disamakan atau diisi default.
4. Fitur `HbA1c_level`
- Data memiliki nilai-nilai yang terdistribusi dalam nilai diskrit atau kategorikal meskipun secara medis harusnya numerik.
- Hal ini menandakan bahwa banyak nilai diatribusi pada angka-angka bulat, seperti 4.0, 5.0, 6.0, dan 7.0.
- Bentuk distribusinya tidak halus (tidak kontinu).
5. Fitur `blood_glucose_level`
- Distribusi tampak diskrit dan berpola, banyak titik spike pada angka tertentu.
- Terdapat lonjakan besar di sekitar nilai 160, menunjukkan kemungkinan data dominan berada di rentang tersebut.
6. Fitur `diabetes`
- Mayoritas nilai adalah 0, menunjukkan bahwa sebagian besar individu dalam dataset tidak menderita diabetes.
- Menunjukkan bahwa dataset tidak seimbang dalam label target, dengan jumlah penderita diabetes jauh lebih sedikit dibanding yang tidak.

### Exploratory Data Analysis - Multivariate Analysis

Pada tahap ini, akan dilakukan analisis data pada fitur kategori dan numerik terhadap target (`diabetes`)

**Categorical Features**
"""

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="diabetes", kind="bar", hue=col, legend=False,
            dodge=False, height=4, aspect=3, data=df, palette="Set3", errorbar=None)
  plt.title("Rata-rata 'diabetes' Relatif terhadap - {}".format(col))

"""**Insight:**
1. Fitur `gender` vs `diabetes`
- Terlihat bahwa rata-rata penderita diabetes lebih tinggi pada kelompok laki-laki (Male) dibandingkan perempuan (Female).
- Nilai rata-rata diabetes untuk kelompok Other hampir nol, disebabkan oleh jumlah data yang sangat sedikit untuk kategori ini, sehingga kurang representatif secara statistik.
- Gender tampaknya memiliki pengaruh terhadap prevalensi diabetes, dengan laki-laki menunjukkan kecenderungan lebih tinggi terkena diabetes dibanding perempuan.
2. Fitur `smoking_history` vs `diabetes`
- Kelompok dengan riwayat merokok former (mantan perokok) menunjukkan rata-rata penderita diabetes tertinggi, mendekati 8%.
- Diikuti oleh kategori ever, not current, dan current dengan tingkat diabetes yang juga relatif tinggi.
- Kategori never memiliki tingkat diabetes yang lebih rendah dibanding mantan atau perokok aktif.
- Kategori Missing memiliki tingkat diabetes terendah, namun ini bisa disebabkan oleh kualitas data atau entri yang tidak lengkap.
- Riwayat merokok berhubungan dengan prevalensi diabetes. Mantan perokok memiliki risiko tertinggi, yang bisa jadi disebabkan oleh dampak kumulatif merokok di masa lalu.

**Numerical Features**
"""

# Mengamati hubungan antar fitur numerik
sns.pairplot(df, diag_kind = 'kde')

"""**Insight:**

Pada pola sebaran data grafik pairplot, terlihat bahwa `age, HbA1c_level, blood_glucose_level, dan bmi` memiliki korelasi yang cukup kuat dengan fitur target diabetes. Hal ini ditunjukkan dengan adanya pola pemisahan yang jelas pada nilai-nilai diabetes (0 dan 1), terutama pada fitur `HbA1c_level dan blood_glucose_level` yang menunjukkan perbedaan distribusi yang signifikan antara penderita dan non-penderita diabetes. Sementara itu, fitur kategorikal biner seperti `hypertension dan heart_disease` terlihat memiliki korelasi yang lebih lemah terhadap diabetes, karena sebaran datanya tidak membentuk pola yang jelas dan masih tercampur antara kelas diabetes 0 dan 1.
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""**Insight:**

Pada heatmap korelasi di atas, fitur `HbA1c_level` memiliki skor korelasi tertinggi dengan fitur target diabetes, yaitu 0.26, diikuti oleh `age dan blood_glucose_level` dengan nilai 0.22, serta `bmi, hypertension dan heart_disease` dengan nilai masing-masing 0.15, 0.16 dan 0.15. Artinya, fitur `HbA1c_level, age, dan blood_glucose_level` memiliki korelasi yang cukup berarti dengan diabetes. Sementara itu, fitur bmi, heart_disease, dan hypertension memiliki korelasi yang cukup lemah terhadap target.

## Data Preparation

Pada bagian ini akan dilakukan 3 tahap persiapan data, yaitu:
- Encoding fitur kategori.
- Pembagian dataset dengan fungsi train_test_split dari library sklearn.
- Standarisasi.

**Encoding Fitur Kategori**
"""

le = LabelEncoder()
df['gender'] = le.fit_transform(df['gender'])

df = pd.concat([df, pd.get_dummies(df['smoking_history'], prefix='smoking_history')],axis=1)
df.drop(['smoking_history'], axis=1, inplace=True)
df.head()

"""**Train-Test-Split**"""

# Pisahkan fitur dan target
X = df.drop(["diabetes"], axis =1)
y = df["diabetes"]

# Split data menjadi train dan test (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

# Tampilkan ukuran hasil split
print("Training set:", X_train.shape)
print("Test set:", X_test.shape)

"""**Standarisasi**"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Modeling

Pada tahap ini, saya akan mengembangkan model machine learning dengan 5 algoritma. Kelima algoritma yang akan digunakan, antara lain:
1. Logistic Regression
2. K-Nearest Neighbor (KNN)
3. Support Vector Classifier (SVC)
4. Decision Tree
5. Random Forest
"""

# Model Logistic
logistic = LogisticRegression(class_weight='balanced', max_iter=1000)
logistic.fit(X_train,y_train)

# Model KNN
knn = KNeighborsClassifier(n_neighbors=5, p=2, weights='distance', metric = 'minkowski')
knn.fit(X_train,y_train)

# Model SVC
svc = SVC(kernel = 'rbf', C=1.0, gamma='scale', class_weight='balanced', probability=True, random_state = 42)
svc.fit(X_train,y_train)

# Model Decision Tree
decisionTree = DecisionTreeClassifier(criterion= 'entropy', class_weight='balanced', random_state=42)
decisionTree.fit(X_train,y_train)

# Model Random Forest
rf = RandomForestClassifier(n_estimators=10, criterion= 'entropy', class_weight='balanced', random_state=42)
rf.fit(X_train,y_train)

"""## Evaluation"""

# Prediksi
y_pred_logreg = logistic.predict(X_test)
y_pred_knn = knn.predict(X_test)
y_pred_svc = svc.predict(X_test)
y_pred_dt = decisionTree.predict(X_test)
y_pred_rf = rf.predict(X_test)

# Inisialisasi tabel evaluasi
model_scores = pd.DataFrame(index=['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc'],
                            columns=['LogisticRegression', 'KNN', 'SVC', 'DecisionTree', 'RandomForest'])

# Logistic Regression
model_scores.loc['accuracy', 'LogisticRegression'] = accuracy_score(y_test, y_pred_logreg)
model_scores.loc['precision', 'LogisticRegression'] = precision_score(y_test, y_pred_logreg)
model_scores.loc['recall', 'LogisticRegression'] = recall_score(y_test, y_pred_logreg)
model_scores.loc['f1_score', 'LogisticRegression'] = f1_score(y_test, y_pred_logreg)
model_scores.loc['roc_auc', 'LogisticRegression'] = roc_auc_score(y_test, logistic.predict_proba(X_test)[:,1])

# KNN
model_scores.loc['accuracy', 'KNN'] = accuracy_score(y_test, y_pred_knn)
model_scores.loc['precision', 'KNN'] = precision_score(y_test, y_pred_knn)
model_scores.loc['recall', 'KNN'] = recall_score(y_test, y_pred_knn)
model_scores.loc['f1_score', 'KNN'] = f1_score(y_test, y_pred_knn)
model_scores.loc['roc_auc', 'KNN'] = roc_auc_score(y_test, knn.predict_proba(X_test)[:,1])

# SVC
model_scores.loc['accuracy', 'SVC'] = accuracy_score(y_test, y_pred_svc)
model_scores.loc['precision', 'SVC'] = precision_score(y_test, y_pred_svc)
model_scores.loc['recall', 'SVC'] = recall_score(y_test, y_pred_svc)
model_scores.loc['f1_score', 'SVC'] = f1_score(y_test, y_pred_svc)
model_scores.loc['roc_auc', 'SVC'] = roc_auc_score(y_test, svc.predict_proba(X_test)[:,1])

# Decision Tree
model_scores.loc['accuracy', 'DecisionTree'] = accuracy_score(y_test, y_pred_dt)
model_scores.loc['precision', 'DecisionTree'] = precision_score(y_test, y_pred_dt)
model_scores.loc['recall', 'DecisionTree'] = recall_score(y_test, y_pred_dt)
model_scores.loc['f1_score', 'DecisionTree'] = f1_score(y_test, y_pred_dt)
model_scores.loc['roc_auc', 'DecisionTree'] = roc_auc_score(y_test, decisionTree.predict_proba(X_test)[:,1])

# Random Forest
model_scores.loc['accuracy', 'RandomForest'] = accuracy_score(y_test, y_pred_rf)
model_scores.loc['precision', 'RandomForest'] = precision_score(y_test, y_pred_rf)
model_scores.loc['recall', 'RandomForest'] = recall_score(y_test, y_pred_rf)
model_scores.loc['f1_score', 'RandomForest'] = f1_score(y_test, y_pred_rf)
model_scores.loc['roc_auc', 'RandomForest'] = roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])

# Tampilkan hasil akhir
print("Hasil Evaluasi Model Klasifikasi:")
model_scores

def plot_confusion_matrix(ax, y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)
    ax.set_title(f'Confusion Matrix - {title}')
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')

# Panggil confusion matrix
fig, axes = plt.subplots(2, 3, figsize=(20, 8))
axes = axes.flatten()

plot_confusion_matrix(axes[0], y_test, y_pred_logreg, "Logistic Regression")
plot_confusion_matrix(axes[1], y_test, y_pred_knn, "KNN")
plot_confusion_matrix(axes[2], y_test, y_pred_svc, "SVC")
plot_confusion_matrix(axes[3], y_test, y_pred_dt, "Decision Tree")
plot_confusion_matrix(axes[4], y_test, y_pred_rf, "Random Forest")

fig.delaxes(axes[5])  # Menghapus subplot terakhir yang tidak dipakai

plt.tight_layout()
plt.show()

# Visualisasi perbandingan akurasi setiap model
accuracy_df = model_scores.loc['accuracy'].reset_index()
accuracy_df.columns = ['Model', 'Accuracy']

plt.figure(figsize=(10, 6))
sns.barplot(x='Accuracy', y='Model', data=accuracy_df, palette='viridis')
plt.title('Perbandingan Akurasi Model Klasifikasi', fontsize=14)
plt.xlabel('Accuracy')
plt.ylabel('Model')
plt.xlim(0.8, 1.0)
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

# Transpose dan ubah ke long format
df_plot = model_scores.T.reset_index().rename(columns={'index': 'Model'})
df_long = pd.melt(df_plot, id_vars='Model', var_name='Metric', value_name='Score')
df_long = df_long[df_long['Metric'] != 'accuracy']

# Plot
plt.figure(figsize=(12, 6))
sns.barplot(data=df_long, x='Model', y='Score', hue='Metric', palette='Set2')

plt.title('Perbandingan Metrik Evaluasi Tiap Model (Tanpa Akurasi)')
plt.ylim(0, 1.1)
plt.xticks(rotation=45)
plt.legend(title='Metric', loc='center left', bbox_to_anchor=(1, 0.5))

for y in [0.2, 0.4, 0.6, 0.8, 1.0]:
    plt.axhline(y=y, color='gray', linestyle='--', linewidth=0.6, alpha=0.6)

plt.tight_layout()
plt.show()

"""**Insight:**

Dari hasil evaluasi di atas, dapat disimpulkan bahwa:
-  Random Forest menunjukkan performa terbaik dengan akurasi, precision, dan F1-score tertinggi, menandakan prediksi yang seimbang dan kemampuan generalisasi yang baik.
- KNN memiliki akurasi tinggi, namun recall rendah, yang berarti model sering gagal mendeteksi kelas positif (banyak false negative), sehingga kurang andal dalam konteks deteksi kasus penting.
- Decision Tree juga memiliki akurasi tinggi, tetapi F1-score dan recall-nya lebih rendah dari Random Forest, menunjukkan performa yang masih belum optimal meskipun cukup stabil.
- Sementara itu, Logistic Regression dan SVC memiliki recall sangat tinggi namun precision rendah, mengindikasikan kecenderungan overpredict kelas positif dan menghasilkan banyak false positive.

## Hyperparameter Tuning on the Best Model

Langkah selanjutnya adalah melakukan hyperparameter tuning pada model terbaik (dalam hal ini Random Forest) untuk mengoptimalkan performa berdasarkan metrik evaluasi.
"""

# Grid parameter yang akan diuji
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt']
}

# Setup GridSearch
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=0
)

# Fit ke data training
grid_search.fit(X_train, y_train)

# Model terbaik hasil tuning
best_rf = grid_search.best_estimator_

# Print parameter terbaik
print("Best parameters found:", grid_search.best_params_)

"""## Model Evaluation After Tuning

Setelah melakukan tuning pada model terbaik, selanjutnya adalah melakukan evaluasi kembali pada modelnya.
"""

# Prediksi
y_pred_best_rf = best_rf.predict(X_test)
y_proba = best_rf.predict_proba(X_test)[:, 1]

# Evaluasi
print("Classification Report:")
print(classification_report(y_test, y_pred_best_rf))

print("Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred_best_rf)
cm_df = pd.DataFrame(cm, index=["Actual 0", "Actual 1"], columns=["Predicted 0", "Predicted 1"])
print(cm_df)

print("ROC AUC:", roc_auc_score(y_test, y_proba))

"""**Insight:**

- Akurasi model tetap tinggi baik sebelum maupun sesudah tuning, menunjukkan performa umum yang kuat. Namun, ini kurang mencerminkan kemampuan model terhadap kelas minoritas.
- Precision kelas 1 meningkat dari 0.84 menjadi 0.88 setelah tuning. Artinya, model hasil tuning lebih tepat dalam mengidentifikasi kasus positif, dengan lebih sedikit false positives.
- Recall kelas 1 sedikit menurun dari 0.52 menjadi 0.51. Artinya, model agak lebih selektif, sehingga sedikit lebih banyak kasus positif yang terlewat (false negatives).
- F1-score kelas 1 meningkat dari 0.64 ke 0.65, menandakan peningkatan keseimbangan antara precision dan recall.
- ROC AUC meningkat signifikan dari 0.8849 menjadi 0.9477, yang menunjukkan peningkatan kemampuan model dalam membedakan antar kelas secara keseluruhan, terlepas dari threshold.
- Confusion matrix sesudah tuning menunjukkan penurunan false positives dan sedikit peningkatan false negatives, yang konsisten dengan perubahan metrik di atas.

Secara keseluruhan, tuning pada model Random Forest berhasil meningkatkan performa keseluruhan, terutama dalam kemampuan membedakan kelas (ROC AUC naik), serta ketepatan prediksi terhadap kelas minoritas (precision dan f1-score naik), meskipun dengan sedikit penurunan pada recall.
"""

# Prediksi train dan test untuk semua model
models = {
    'LogisticRegression': logistic,
    'KNN': knn,
    'SVC': svc,
    'DecisionTree': decisionTree,
    'RandomForest': rf,
    'RandomForest (setelah tuning)': best_rf
}

train_accuracies = {}
test_accuracies = {}

for name, model in models.items():
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    train_accuracies[name] = accuracy_score(y_train, y_train_pred)
    test_accuracies[name] = accuracy_score(y_test, y_test_pred)

# Buat DataFrame
accuracy_table = pd.DataFrame({
    'train': train_accuracies,
    'test': test_accuracies
})

# Transpose agar model jadi baris
accuracy_table = accuracy_table.T

# Tampilkan
accuracy_table

"""**Insight:**

Berdasarkan hasil di atas, model Random Forest setelah tuning sangat baik, dengan akurasi tinggi dan generalisasi kuat. Tidak terlihat tanda overfitting yang serius. Sehingga menjadi model terbaik untuk proyek ini.
"""

sns.set(style="whitegrid")

# Buat dataframe hasil
import pandas as pd
df_rf = pd.DataFrame({'Aktual': y_test, 'Prediksi': y_pred_best_rf})

# Plot perbandingan
plt.figure(figsize=(8,5))
sns.countplot(data=df_rf.melt(), x='value', hue='variable', palette='Set2')
plt.title('Perbandingan Hasil Prediksi dan Nilai Aktual (Random Forest - setelah tuning)')
plt.xlabel('Kelas')
plt.ylabel('Jumlah')
plt.legend(title='Tipe Nilai')
plt.show()

feature_names = ['age', 'gender', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level',
                 'blood_glucose_level', 'smoking_history_Missing', 'smoking_history_current', 'smoking_history_ever',
                 'smoking_history_former', 'smoking_history_never', 'smoking_history_not current']

importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_rf.feature_importances_
}).sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(data=importance_df, x='Importance', y='Feature', hue='Feature', legend=False, palette='viridis')
plt.title('Feature Importance - Random Forest (setelah tuning)')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.tight_layout()
plt.show()

"""Berdasarkan features importance di atas, berikut adalah fitur-fitur yang paling berpengaruh dalam terhadap prediksi diabetes:
1. `HbA1c_level` (Kadar HbA1c)
Fitur ini adalah yang paling berpengaruh dalam model. HbA1c mencerminkan kadar gula darah rata-rata dalam beberapa bulan terakhir. Nilai yang tinggi menunjukkan risiko diabetes yang lebih besar, sehingga sangat berpengaruh dalam menentukan prediksi, kemungkinan terkait risiko komplikasi kesehatan.
2. `blood_glucose_level` (Kadar Glukosa Darah)
Kadar glukosa darah juga menjadi faktor penting. Glukosa darah yang tinggi bisa menandakan kondisi prediabetes atau diabetes, yang merupakan indikator utama dalam risiko kesehatan jangka panjang.
3. `gender` (Jenis Kelamin)
Jenis kelamin juga memainkan peran penting. Dalam banyak studi medis, risiko terhadap penyakit tertentu bisa berbeda antara pria dan wanita, sehingga gender dapat memengaruhi prediksi model, terutama untuk kondisi metabolik atau kardiovaskular.
4. `bmi` (Indeks Massa Tubuh)
BMI menunjukkan proporsi berat terhadap tinggi badan dan menjadi indikator obesitas. Nilai BMI yang tinggi sering dikaitkan dengan risiko penyakit seperti jantung, hipertensi, dan diabetes, sehingga model memberi bobot cukup tinggi pada fitur ini.
"""